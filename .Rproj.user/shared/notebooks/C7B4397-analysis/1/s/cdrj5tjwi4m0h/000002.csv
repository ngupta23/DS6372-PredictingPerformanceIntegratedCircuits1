"0","plot.diagnostics <-  function(model, train) {"
"0","  plot(model)"
"0","  "
"0","  residuals = resid(model) # Plotted above in plot(lm.out)"
"0","  r.standard = rstandard(model)"
"0","  r.student = rstudent(model)"
"0","  plot(predict(model,train),r.student,"
"0","      ylab=""Student Residuals"", xlab=""Predicted Values"", "
"0","      main=""Student Residual Plot"") "
"0","  abline(0, 0)"
"0","  "
"0","  plot(predict(model, train),r.standard,"
"0","      ylab=""Standard Residuals"", xlab=""Predicted Values"", "
"0","      main=""Standard Residual Plot"") "
"0","  abline(0, 0)"
"0","  abline(2, 0)"
"0","  abline(-2, 0)"
"0","  "
"0","  # Histogram"
"0","  hist(r.student, freq=FALSE, main=""Distribution of Studentized Residuals"", "
"0","  xlab=""Studentized Residuals"", ylab=""Density"", ylim=c(0,0.5))"
"0","  # Create range of x-values for normal curve"
"0","  xfit <- seq(min(r.student)-1, max(r.student)+1, length=40)"
"0","  # Generate values from the normal distribution at the specified values"
"0","  yfit <- (dnorm(xfit))"
"0","  # Add the normal curve"
"0","  lines(xfit, yfit, ylim=c(0,0.5))"
"0","  "
"0","  "
"0","  # http://www.stat.columbia.edu/~martin/W2024/R7.pdf"
"0","  # Influential plots"
"0","  inf.meas = influence.measures(model)"
"0","  # print (summary(inf.meas)) # too much data"
"0","  "
"0","  # Leverage plot"
"0","  lev = hat(model.matrix(model))"
"0","  plot(lev, ylab = 'Leverage - check')"
"0","  "
"0","  # Cook's Distance"
"0","  cd = cooks.distance(model)"
"0","  plot(cd,ylab=""Cooks distances"")"
"0","  abline(4/nrow(train),0)"
"0","  abline(1,0)"
"0","  "
"0","  print (paste(""Number of data points that have Cook's D > 4/n: "", length(cd[cd > 4/nrow(train)]), sep = """")) "
"0","  print (paste(""Number of data points that have Cook's D > 1: "", length(cd[cd > 1]), sep = """")) "
"0","  return(cd)"
"0","}"
"0","# https://stackoverflow.com/questions/48265743/linear-model-subset-selection-goodness-of-fit-with-k-fold-cross-validation"
"0","# changes slightly since call[[2]] was just returning ""formula"" without actually returnign the value in formula"
"0","predict.regsubsets <- function(object, newdata, id, formula, ...) {"
"0","    #form <- as.formula(object$call[[2]])"
"0","    mat <- model.matrix(formula, newdata) # adds intercept and expands any interaction terms"
"0","    coefi <- coef(object, id = id)"
"0","    xvars <- names(coefi)"
"0","    return(mat[,xvars]%*%coefi)"
"0","}"
"0","  "
"0","test.model = function(model, test, type = 'No Model Name Specified', level = 0.95, regsubset = FALSE, id, formula){"
"0","  ## if using caret for glm select equivalent functionality, "
"0","  ## need to set regsubset = TRUE, pass id of best model through id variable, "
"0","  ## and pass formula (full is ok as it will select subset of variables from there)"
"0","  if (regsubset == FALSE){"
"0","    pred = predict(model, newdata=test, interval=""confidence"", level = level) "
"0","  }"
"0","  "
"0","  if (regsubset == TRUE){"
"0","    pred = predict.regsubsets(model, newdata = test, id = id, formula = formula)"
"0","  }"
"0","  "
"0","  # Summary of predicted values"
"0","  print (""Summary of predicted values: "")"
"0","  print(summary(pred[,1]))"
"0","  "
"0","  test.mse = mean((test[,label.names]-pred[,1])^2)"
"0","  print (paste(type, "" Test MSE: "", test.mse, sep=""""))"
"0","  "
"0","  plot(test[,label.names],pred[,1],xlab = ""Actual"", ylab = ""Predicted"")"
"0","}"
