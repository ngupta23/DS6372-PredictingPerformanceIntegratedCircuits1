---
title: "Model Analysis"
author: "Nikhil Gupta"
date: "`r Sys.time()`"
output:
 html_document:
   toc: true
   toc_float: true
   toc_depth: 5
params:
  output.var: 'y3'
  transform.abs: FALSE
  log.pred: FALSE
  eda: FALSE
  algo.forward: FALSE
  algo.backward: FALSE
  algo.stepwise: FALSE
  algo.LASSO: FALSE
  algo.LARS: FALSE
  
  algo.forward.caret: TRUE
  algo.backward.caret: FALSE
  algo.stepwise.caret: FALSE
  algo.LASSO.caret: FALSE
  algo.LARS.caret: FALSE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
sessionInfo()
```

```{r include=FALSE}
# https://gist.github.com/smithdanielle/9913897
check.packages <- function(pkg){
    new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
    if (length(new.pkg))
        install.packages(new.pkg, dependencies = TRUE)
    #sapply(pkg, require, character.only = TRUE)
    sapply(pkg, library, character.only = TRUE) # see comment below in GitHub repo
}

# Usage example
packages<-c("dplyr", "DT", "mosaic", "MASS", "usdm", "tidyverse", "ggplot2", "PerformanceAnalytics", "caTools", "glmnet", "caret","leaps")
check.packages(packages)

library(dplyr)
library(DT)
library(mosaic)
library(MASS)
library(usdm) #for multicollinearity
library(tidyverse)
library(ggplot2)
library(PerformanceAnalytics)
library(caTools)
library(glmnet)
library(caret)
library(leaps)
```

# User Inputs
```{r User Inputs}
output.var = params$output.var 
transform.abs = params$transform.abs
log.pred = params$log.pred
eda = params$eda
algo.forward = params$algo.forward
algo.backward = params$algo.backward
algo.stepwise = params$algo.stepwise
algo.LASSO = params$algo.LASSO
algo.LARS = params$algo.LARS
  
algo.forward.caret = params$algo.forward.caret
algo.backward.caret = params$algo.backward.caret
algo.stepwise.caret = params$algo.stepwise.caret
algo.LASSO.caret = params$algo.LASSO.caret
algo.LARS.caret = params$algo.LARS.caret

message("Parameters used for training/prediction: ")
str(params)
```

```{r}
# Setup Labels
# alt.scale.label.name = Alternate Scale variable name
#   - if predicting on log, then alt.scale is normal scale
#   - if predicting on normal scale, then alt.scale is log scale
if (log.pred == TRUE){
  label.names = paste('log.',output.var,sep="")
  alt.scale.label.name = output.var
}
if (log.pred == FALSE){
  label.names = output.var
  alt.scale.label.name = paste('log.',output.var,sep="")
}
```


# Prepare Data

## Read and Clean Features
```{r}
features = read.csv("../../Data/features.csv")
#str(features) 
```


### Checking correlations to evaluate removal of redundant features
```{r Correlation of inputs to each other}
corr.matrix = round(cor(features[sapply(features, is.numeric)]),2)

# filter out only highly correlated variables
threshold = 0.6
corr.matrix.tmp = corr.matrix
diag(corr.matrix.tmp) = 0
high.corr = apply(abs(corr.matrix.tmp) >= threshold, 1, any)
high.corr.matrix = corr.matrix.tmp[high.corr, high.corr]

DT::datatable(corr.matrix)
DT::datatable(high.corr.matrix)
```


### Feature Names
```{r}
feature.names = colnames(features)
drops <- c('JobName')
feature.names = feature.names[!(feature.names %in% drops)]
#str(feature.names)
```

## Read and Clean Labels
```{r}
labels = read.csv("../../Data/labels.csv")
#str(labels)
labels = labels[,c("JobName", output.var)]
summary(labels)
```

## Merge Datasets
```{r}
data <- merge(features, labels, by = 'JobName')
drops <- c('JobName')
data = data[,(!colnames(data) %in% drops)]
#str(data)
```

## Transformations
```{r Transformations}
if (transform.abs == TRUE){
  data[,label.names] = 10^(data[,label.names]/20)
  data = filter(data, y3 < 1E7)
}


#str(data)
if (log.pred == TRUE){
  data[label.names] = log(data[alt.scale.label.name],10)
  
  drops = c(alt.scale.label.name)
  data = data[!(names(data) %in% drops)]
}
#str(data)
```

## Remove NA Cases
```{r}
data = data[complete.cases(data),]
```

# Exploratory Data Analysis

## Check correlation of Label with Featires
```{r Correlation of features to label}
if (eda == TRUE){
  corr.to.label =round(cor(dplyr::select(data,-one_of(label.names)),dplyr::select_at(data,label.names)),4)
  DT::datatable(corr.to.label)
}
```

## Multicollinearity - VIF
```{r vif}
if (eda == TRUE){
  vifDF = usdm::vif(select_at(data,feature.names)) %>% arrange(desc(VIF))
  head(vifDF,10)
}
```

## Scatterplots
```{r}
panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}
```

```{r Histogram}
if (eda == TRUE){
  histogram(data[ ,label.names])
  #hist(data[complete.cases(data),alt.scale.label.name])
}
```

```{r Scatterplots}
# https://stackoverflow.com/questions/24648729/plot-one-numeric-variable-against-n-numeric-variables-in-n-plots
ind.pairs.plot <- function(data, xvars=NULL, yvar)
{
    df <- data
    if (is.null(xvars)) {
        xvars = names(data[which(names(data)!=yvar)])       
    }   

    #choose a format to display charts
    ncharts <- length(xvars) 
    
    for(i in 1:ncharts){    
        plot(df[,xvars[i]],df[,yvar], xlab = xvars[i], ylab = yvar)
    }
}

if (eda == TRUE){
  ind.pairs.plot(data, feature.names, label.names)
}


# 
# pl <- ggplot(data, aes(x=x18, y = y3))
# pl2 <- pl + geom_point(aes(alpha = 0.1)) # default color gradient based on 'hp'
# print(pl2)

```


## Feature Engineering
```{r}
if(eda ==FALSE){
  # x18 may need transformations
  plot(data[,'x18'], data[,label.names], main = "Original Scatter Plot vs. x18", ylab = label.names, xlab = 'x18')
  plot(sqrt(data[,'x18']), data[,label.names], main = "Original Scatter Plot vs. sqrt(x18)", ylab = label.names, xlab = 'sqrt(x18)')
  
  # transforming x18
  data$sqrt.x18 = sqrt(data$x18)
  data = dplyr::select(data,-one_of('x18'))
  
  # what about x7, x9?
  # x11 looks like data is at discrete points after a while. Will this be a problem?
}
```


# Modeling


##  Train Test Split

```{r}
data = data[sample(nrow(data)),] # randomly shuffle data
split = sample.split(data[,label.names], SplitRatio = 0.8)

data.train = subset(data, split == TRUE)
data.test = subset(data, split == FALSE)
```

## Common Functions
```{r}
plot.diagnostics <-  function(model, train) {
  plot(model)
  
  residuals = resid(model) # Plotted above in plot(lm.out)
  r.standard = rstandard(model)
  r.student = rstudent(model)

  plot(predict(model,train),r.student,
      ylab="Student Residuals", xlab="Predicted Values", 
      main="Student Residual Plot") 
  abline(0, 0)
  
  plot(predict(model, train),r.standard,
      ylab="Standard Residuals", xlab="Predicted Values", 
      main="Standard Residual Plot") 
  abline(0, 0)
  abline(2, 0)
  abline(-2, 0)
  
  # Histogram
  hist(r.student, freq=FALSE, main="Distribution of Studentized Residuals", 
  xlab="Studentized Residuals", ylab="Density", ylim=c(0,0.5))

  # Create range of x-values for normal curve
  xfit <- seq(min(r.student)-1, max(r.student)+1, length=40)

  # Generate values from the normal distribution at the specified values
  yfit <- (dnorm(xfit))

  # Add the normal curve
  lines(xfit, yfit, ylim=c(0,0.5))
  
  
  # http://www.stat.columbia.edu/~martin/W2024/R7.pdf
  # Influential plots
  inf.meas = influence.measures(model)
  # print (summary(inf.meas)) # too much data
  
  # Leverage plot
  lev = hat(model.matrix(model))
  plot(lev, ylab = 'Leverage - check')
  
  # Cook's Distance
  cd = cooks.distance(model)
  plot(cd,ylab="Cooks distances")
  abline(4/nrow(train),0)
  abline(1,0)
  
  print (paste("Number of data points that have Cook's D > 4/n: ", length(cd[cd > 4/nrow(train)]), sep = "")) 
  print (paste("Number of data points that have Cook's D > 1: ", length(cd[cd > 1]), sep = "")) 
  return(cd)
}

# https://stackoverflow.com/questions/48265743/linear-model-subset-selection-goodness-of-fit-with-k-fold-cross-validation
# changes slightly since call[[2]] was just returning "formula" without actually returnign the value in formula
predict.regsubsets <- function(object, newdata, id, formula, ...) {
    #form <- as.formula(object$call[[2]])
    mat <- model.matrix(formula, newdata) # adds intercept and expands any interaction terms
    coefi <- coef(object, id = id)
    xvars <- names(coefi)
    return(mat[,xvars]%*%coefi)
}
  
test.model = function(model, test, type = 'No Model Name Specified', level = 0.95, regsubset = FALSE, id, formula){
  ## if using caret for glm select equivalent functionality, 
  ## need to set regsubset = TRUE, pass id of best model through id variable, 
  ## and pass formula (full is ok as it will select subset of variables from there)
  if (regsubset == FALSE){
    pred = predict(model, newdata=test, interval="confidence", level = level) 
  }
  
  if (regsubset == TRUE){
    pred = predict.regsubsets(model, newdata = test, id = id, formula = formula)
  }
  
  # Summary of predicted values
  print ("Summary of predicted values: ")
  print(summary(pred[,1]))
  
  test.mse = mean((test[,label.names]-pred[,1])^2)
  print (paste(type, " Test MSE: ", test.mse, sep=""))
  
  plot(test[,label.names],pred[,1],xlab = "Actual", ylab = "Predicted")
}

```

## Setup Formulae
```{r}
n <- names(data.train)
formula <- as.formula(paste(paste(n[n %in% label.names], collapse = " + ")," ~", paste(n[!n %in% label.names], collapse = " + "))) 
grand.mean.formula = as.formula(paste(paste(n[n %in% label.names], collapse = " + ")," ~ 1"))
print(formula)
print(grand.mean.formula)

# Update feature.names because we may have transformed some features
feature.names = n[!n %in% label.names]
```

## Full & Grand Means Model

```{r Full Model}
model.full = lm(formula , data.train)
summary(model.full)
cd.full = plot.diagnostics(model.full, data.train)
```

## Just trial removing all high influence points
```{r}
high.cd = names(cd.full[cd.full > 4/nrow(data.train)])
data.train2 = data.train[!(rownames(data.train)) %in% high.cd,]
model.full2 = lm(formula , data.train2)
summary(model.full2)
cd.full2 = plot.diagnostics(model.full2, data.train2)

# much more normal residuals than before. 
# See if you can check the distribution (boxplots) of the high leverage points and the other points
```

```{r}
model.null = lm(grand.mean.formula, data.train)
summary(model.null)
plot.diagnostics(model.null, data.train)
```

```{r}
model.null2 = lm(grand.mean.formula, data.train2)
summary(model.null2)
plot.diagnostics(model.null2, data.train2)
```
## Variable Selection 
http://www.stat.columbia.edu/~martin/W2024/R10.pdf 

TODO: 
Cross Validation + Other Metrics: http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/

### Forward Selection (w/ full train)

#### Train
```{r Forward Selection}
if (algo.forward == TRUE){
  t1 = Sys.time()
  
  model.forward = step(model.null, scope=list(lower=model.null, upper=model.full), direction="forward", trace = 0)
  print(summary(model.forward))
  #saveRDS(model.forward,file = "model_forward.rds")
  
  t2 = Sys.time()
  print (paste("Time taken for Forward Selection: ",t2-t1, sep = ""))
  
  plot.diagnostics(model.forward, data.train)
}
```

#### Test
```{r}
if (algo.forward == TRUE){
  test.model(model.forward, data.test, "Forward Selection")
}
```

### Forward Selection (w/ filtered train)

#### Train
```{r Forward Selection with Filtered}
if (algo.forward == TRUE){
  t1 = Sys.time()
  
  model.forward2 = step(model.null2, scope=list(lower=model.null2, upper=model.full2), direction="forward", trace = 0)
  print(summary(model.forward2))
  #saveRDS(model.forward,file = "model_forward.rds")
  
  t2 = Sys.time()
  print (paste("Time taken for Forward Selection: ",t2-t1, sep = ""))
  
  plot.diagnostics(model.forward2, data.train2)
}
```

#### Test
```{r}
if (algo.forward == TRUE){
  test.model(model.forward2, data.test, "Forward Selection (2)")
}
```


### Forward Selection with Caret (w/ full train)# http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/

#### Common Functions
```{r}
train.caret.glmselect = function(formula, data, method, feature.names, train.control = NULL){
  
  if(is.null(train.control)){
    train.control <- trainControl(method = "cv"
                              ,number = 10
                              ,search = "grid"
                              ,verboseIter = TRUE
                              )
  }
  
  set.seed(1)
  model.caret <- caret::train(formula
                              , data = data
                              , method = method
                              , tuneGrid = data.frame(nvmax = 1:length(feature.names))
                              , trControl = train.control
                              )
  
  print(model.caret$results) # all model results
  print(model.caret$bestTune) # best model
  
  model = model.caret$finalModel
  
  # Provides the coefficients of the best model
  id = rownames(model.caret$bestTune)
  message("Coefficients of final model:")
  print (coef(model, id = id))
  
  # Need to find alternate to plotting diagnostic plots
  # plot.diagnostics(model.forward,data.train)
  # plot(model.forward,labels = colnames(data.train),scale=c("bic")) ## too many variables
  return(list(model = model,id = id))
}
```

#### Train
```{r}
if (algo.forward.caret == TRUE){
  # train.control <- trainControl(method = "cv"
  #                             ,number = 10
  #                             ,search = "grid"
  #                             ,verboseIter = TRUE
  #                             )
  # 
  # set.seed(1)
  # model.forward.caret <- caret::train(formula
  #                                   , data = data.train
  #                                   , method = "leapForward"
  #                                   , tuneGrid = data.frame(nvmax = 1:length(feature.names))
  #                                  , trControl = train.control
  #                             )
  # 
  # print(model.forward.caret$results) # all model results
  # print(model.forward.caret$bestTune) # best model
  # 
  # model.forward = model.forward.caret$finalModel
  # 
  # # Provides the coefficients of the best model
  # id = rownames(model.forward.caret$bestTune)
  # coef(model.forward, id = id)
  # 
  # # Need to find alternate to plotting diagnostic plots
  # # plot.diagnostics(model.forward,data.train)
  # # plot(model.forward,labels = colnames(data.train),scale=c("bic")) ## too many variables
  
  returned = train.caret.glmselect(formula, data.train, "leapForward", feature.names)
  model.forward = returned$model
  id = returned$id
}
```

#### Test
```{r}
if (algo.forward.caret == TRUE){
  test.model(model.forward, data.test, "Forward Selection", regsubset = TRUE, id = id, formula = formula)
}
```

### Forward Selection with Caret (w/ filtered train)

#### Train
```{r}
if (algo.forward.caret == TRUE){
  # train.control <- trainControl(method = "cv"
  #                             ,number = 10
  #                             ,search = "grid"
  #                             ,verboseIter = TRUE
  #                             )
  # 
  # set.seed(1)
  # model.forward.caret <- caret::train(formula
  #                                   , data = data.train2
  #                                   , method = "leapForward"
  #                                   , tuneGrid = data.frame(nvmax = 1:length(feature.names))
  #                                  , trControl = train.control
  #                             )
  # 
  # print(model.forward.caret$results) # all model results
  # print(model.forward.caret$bestTune) # best model
  # 
  # model.forward = model.forward.caret$finalModel
  # 
  # # Provides the coefficients of the best model
  # id = rownames(model.forward.caret$bestTune)
  # coef(model.forward, id = id)
  # 
  # # Need to find alternate to plotting diagnostic plots
  # # plot.diagnostics(model.forward,data.train)
  # # plot(model.forward,labels = colnames(data.train),scale=c("bic")) ## too many variables
  
  returned = train.caret.glmselect(formula, data.train2, "leapForward", feature.names)
  model.forward = returned$model
  id = returned$id
}
```

#### Test
```{r}
if (algo.forward.caret == TRUE){
  test.model(model.forward, data.test, "Forward Selection (2)", regsubset = TRUE, id = id, formula = formula)
}
```

### Backward Elimination

#### Train
```{r Backward Elimination}
if (algo.backward == TRUE){
  # Takes too much time
  t1 = Sys.time()
  
  model.backward = step(model.full, data = data.train, direction="backward", trace = 0)
  print(summary(model.backward))
  #saveRDS(model.forward,file = "model_backward.rds")
  
  t2 = Sys.time()
  print (paste("Time taken for Backward Elimination: ",t2-t1, sep = ""))
  
  plot.diagnostics(model.backward, data.train)
}
```

#### Test
```{r}
if (algo.backward == TRUE){
  test.model(model.backard, data.test, "Backward Elimination")
}
```

### Stepwise Selection (w/ full train)

#### Train
```{r Stepwise Selection}
if (algo.stepwise == TRUE){
  t1 = Sys.time()
  
  model.stepwise = step(model.null, scope=list(upper=model.full), data = data.train, direction="both", trace = 0)
  print(summary(model.stepwise))
  #saveRDS(model.stepwise,file = "model_stepwise.rds")
  
  t2 = Sys.time()
  print (paste("Time taken for Stepwise Selection: ",t2-t1, sep = ""))
  
  plot.diagnostics(model.stepwise, data.train)
}
```

#### Test
```{r}
if (algo.stepwise == TRUE){
  test.model(model.stepwise, data.test, "Stepwise Selection")
}
```

### Stepwise Selection (w/ filtered train)

#### Train
```{r Stepwise Selection with filtered data}
if (algo.stepwise == TRUE){
  t1 = Sys.time()
  
  model.stepwise2 = step(model.null2, scope=list(upper=model.full2), data = data.train2, direction="both", trace = 0)
  print(summary(model.stepwise2))
  #saveRDS(model.forward,file = "model_stepwise.rds")
  
  t2 = Sys.time()
  print (paste("Time taken for Stepwise Selection: ",t2-t1, sep = ""))
  
  plot.diagnostics(model.stepwise2, data.train2)
}
```

#### Test
```{r}
if (algo.stepwise == TRUE){
  test.model(model.stepwise2, data.test, "Stepwise Selection (2)")
}
```


### Stepwise Selection with Caret (w/ full train)# http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/

#### Train
```{r Stepwise Selection using caret}
if (algo.stepwise.caret == TRUE){
  train.control <- trainControl(method = "cv"
                              ,number = 10
                              ,search = "grid"
                              ,verboseIter = TRUE
                              )
  
  set.seed(1)
  model.stepwise.caret <- caret::train(formula
                                    , data = data.train
                                    , method = "leapSeq"
                                    , tuneGrid = data.frame(nvmax = 1:length(feature.names))
                                    , trControl = train.control
                              )
  
  print(model.stepwise.caret$results) # all model results
  print(model.stepwise.caret$bestTune) # best model
  
  model.stepwise = model.stepwise.caret$finalModel
  
  # Provides the coefficients of the best model
  id = rownames(model.stepwise.caret$bestTune)
  coef(model.forward, id = id)
  
  # Need to find alternate to plotting diagnostic plots
  # plot.diagnostics(model.forward,data.train)
  # plot(model.forward,labels = colnames(data.train),scale=c("bic")) ## too many variables
}
```

#### Test
```{r}
if (algo.stepwise.caret == TRUE){
  test.model(model.stepwise, data.test, "Stepwise Selection", regsubset = TRUE, id = id, formula = formula)
}
```

### Forward Selection with Caret (w/ filtered train)

#### Train
```{r Stepwise Selection using caret filtered}
if (algo.stepwise.caret == TRUE){
  train.control <- trainControl(method = "cv"
                              ,number = 10
                              ,search = "grid"
                              ,verboseIter = TRUE
                              )
  
  set.seed(1)
  model.stepwise.caret <- caret::train(formula
                                    , data = data.test
                                    , method = "leapSeq"
                                    , tuneGrid = data.frame(nvmax = 1:length(feature.names))
                                    , trControl = train.control
                              )
  
  print(model.stepwise.caret$results) # all model results
  print(model.stepwise.caret$bestTune) # best model
  
  model.stepwise = model.stepwise.caret$finalModel
  
  # Provides the coefficients of the best model
  id = rownames(model.stepwise.caret$bestTune)
  coef(model.forward, id = id)
  
  # Need to find alternate to plotting diagnostic plots
  # plot.diagnostics(model.forward,data.train)
  # plot(model.forward,labels = colnames(data.train),scale=c("bic")) ## too many variables
}
```

#### Test
```{r}
if (algo.stepwise.caret == TRUE){
  test.model(model.stepwise, data.test, "Stepwise Selection", regsubset = TRUE, id = id, formula = formula)
}
```


### LASSO (w/ full train)
#### Train
```{r LASSO With full}
if(algo.LASSO == TRUE){
  # Formatting data for GLM net
  # you can use model.matrix as well -- model.matrix creates a design (or model) matrix, 
  # e.g., by expanding factors to a set of dummy variables (depending on the contrasts) 
  # and expanding interactions similarly.
  x = as.matrix(data.train[,feature.names])
  y = data.train[,label.names]
  
  xtest = as.matrix(data.test[,feature.names]) 
  ytest = data.test[,label.names] 
  
  grid=10^seq(10,-2, length =100)
  
  set.seed(1)
  model.LASSO=glmnet(x,y,alpha=1, lambda =grid)
  
  cv.out=cv.glmnet(x,y,alpha=1) # alpha=1 performs LASSO
  plot(cv.out)
  bestlambda<-cv.out$lambda.min  # Optimal penalty parameter.  You can make this call visually.
  
  print(coef(model.LASSO,s=bestlambda))
}
```

#### Test
```{r}
if(algo.LASSO == TRUE){
  lasso.pred=predict (model.LASSO ,s=bestlambda ,newx=xtest)
  
  testMSE_LASSO = mean((ytest-lasso.pred)^2)
  print (paste("LASSO Test RMSE: ",testMSE_LASSO, sep=""))
  
  plot(ytest,lasso.pred)
}
```

### LASSO (w/ filtered train)
#### Train
```{r LASSO with high Cooks D filtered}
if(algo.LASSO == TRUE){
  # Formatting data for GLM net
  # you can use model.matrix as well -- model.matrix creates a design (or model) matrix, 
  # e.g., by expanding factors to a set of dummy variables (depending on the contrasts) 
  # and expanding interactions similarly.
  x = as.matrix(data.train2[,feature.names])
  y = data.train2[,label.names]
  
  xtest = as.matrix(data.test[,feature.names]) 
  ytest = data.test[,label.names] 
  
  grid=10^seq(10,-2, length =100)
  
  set.seed(1)
  model.LASSO=glmnet(x,y,alpha=1, lambda =grid)
  
  cv.out=cv.glmnet(x,y,alpha=1) # alpha=1 performs LASSO
  plot(cv.out)
  bestlambda<-cv.out$lambda.min  # Optimal penalty parameter.  You can make this call visually.
  
  print(coef(model.LASSO,s=bestlambda))
}
```

#### Test
```{r}
if(algo.LASSO == TRUE){
  lasso.pred=predict (model.LASSO ,s=bestlambda ,newx=xtest)  
  
  testMSE_LASSO = mean((ytest-lasso.pred)^2)
  print (paste("LASSO Test RMSE: ",testMSE_LASSO, sep=""))
  
  plot(ytest,lasso.pred)
}
```

### LASSO with Caret (w/ full train)
#### Train
```{r}
if (algo.LASSO.caret == TRUE){
  train.control <- trainControl(method = "cv"
                              ,number = 10
                              ,search = "grid"
                              ,verboseIter = TRUE
                              )
  
  lambda = 10^seq(-2,2, length =100)
  alpha = c(1)
  
  tune.grid = expand.grid(alpha = alpha,lambda = lambda)
  
  # Will only show 1 Lambda value, but that is OK
  # https://stackoverflow.com/questions/47526544/why-need-to-tune-lambda-with-carettrain-method-glmnet-and-cv-glmnet
  set.seed(1)
  model.LASSO.caret <- caret::train(formula
                                  ,data = data.train 
                                  ,method = "glmnet" 
                                  ,trControl = train.control
                                  ,tuneGrid = tune.grid
                                   )
  
  
  print(model.LASSO.caret)
  plot(model.LASSO.caret)
  
  model.LASSO.caret$bestTune
  summary(model.LASSO.caret$finalModel)
  #coef(model.LASSO.caret$finalModel)
}
```


#### Test
```{r}
if (algo.LASSO.caret == TRUE){
  xtest = as.matrix(data.test[,feature.names]) 
  ytest = data.test[,label.names] 
  
  lasso.pred=predict(model.LASSO.caret, xtest )  
 
  testMSE_LASSO = mean((ytest-lasso.pred)^2)
  print (paste("LASSO Test RMSE: ",testMSE_LASSO, sep=""))
    
  plot(ytest,lasso.pred)
}
```


### LASSO with Caret (w/ filtered dataset)
#### Train
```{r}
if (algo.LASSO.caret == TRUE){
  train.control <- trainControl(method = "cv"
                              ,number = 10
                              ,search = "grid"
                              ,verboseIter = TRUE
                              )
  
  lambda = 10^seq(-2,2, length =100)
  alpha = c(1)
  
  tune.grid = expand.grid(alpha = alpha,lambda = lambda)
  
  # Will only show 1 Lambda value, but that is OK
  # https://stackoverflow.com/questions/47526544/why-need-to-tune-lambda-with-carettrain-method-glmnet-and-cv-glmnet
  set.seed(1)
  model.LASSO.caret <- caret::train(formula
                                  ,data = data.train2 
                                  ,method = "glmnet" 
                                  ,trControl = train.control
                                  ,tuneGrid = tune.grid
                                   )
  
  
  print(model.LASSO.caret)
  plot(model.LASSO.caret)
  
  model.LASSO.caret$bestTune
  summary(model.LASSO.caret$finalModel)
  #coef(model.LASSO.caret$finalModel)
}
```


#### Test
```{r}
if (algo.LASSO.caret == TRUE){
  xtest = as.matrix(data.test[,feature.names]) 
  ytest = data.test[,label.names] 
  
  lasso.pred=predict(model.LASSO.caret, xtest )  
 
  testMSE_LASSO = mean((ytest-lasso.pred)^2)
  print (paste("LASSO Test RMSE (2): ",testMSE_LASSO, sep=""))
    
  plot(ytest,lasso.pred)
}
```


```{r}
```



