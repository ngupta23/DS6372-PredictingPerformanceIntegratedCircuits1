geom_density() +
facet_wrap(~key, scales = 'free',ncol=4)
ggplot(gather(select_at(df,c('y3','y3log','x18','x18sqrt'))), aes(value)) +
geom_histogram(aes(y=..density..),bins = 50,fill='light blue') +
geom_density() +
facet_wrap(~key, scales = 'free',ncol=4)
df=df %>%
select(-JobName,-x18aqrt,-y3)
df=df %>%
select(-JobName,-x18sqrt,-y3)
df.train = df %>% sample_frac(.70)
df.train
names(df.train)
df.test = df %>% anti_join(df, df.train, by = 'id')
df=data.complete %>%
mutate(x18sqrt = sqrt(x18)
,y3log = log(y3)
)
ggplot(gather(select_at(df,c('y3','y3log','x18','x18sqrt'))), aes(value)) +
geom_histogram(aes(y=..density..),bins = 50,fill='light blue') +
geom_density() +
facet_wrap(~key, scales = 'free',ncol=4)
df=df %>%
select(-x18sqrt,-y3)
df.train = df %>% sample_frac(.70)
df.test = df %>% anti_join(df, df.train, by = 'JobName')
lm(data=select(df.train,-JobName), formula = y3log ~)
model = lm(data=select(df.train,-JobName), formula = y3log ~ .)
summary(model)
res=resid(model)
plot(data$a,  res)
plot(df$y13log,  res)
res
plot(df$y13log,  res)
nrow(res)
length(res)
nrow(df)
model = lm(data=select(df.train,-JobName), formula = y3log ~ .)
res=resid(model)
any(is.na(df$y3))
any(is.null(df$y3))
investr::plotFit(model,interval=c('both'),level=0.95, extend.range=T,shade=T)
install.packages('investr')
knitr::opts_chunk$set(echo = FALSE)
library(usdm) #for multicollinearity
library(tidyverse)
library(ggplot2)
library(PerformanceAnalytics)
library(investr)
investr::plotFit(model,interval=c('both'),level=0.95, extend.range=T,shade=T)
investr::plotFit(model,data=df,interval=c('both'),level=0.95, extend.range=T,shade=T)
plot(predict(model,data),resid(model))
anova(model)
Metrics::mse(df$y3log,predict(model,df))
install.packages('Metrics')
Metrics::mse(df$y3log,predict(model,df))
plot(model, which=c(1:3))
par(mfrow=c(2,2))
plot(model, which=c(1:3))
studresbrain <- rstudent(model)
studresbrain
hist(stud, freq=FALSE, main="Distribution of Studentized Residuals",
xlab="Studentized Residuals", ylab="Density", ylim=c(0,0.5))
stud <- rstudent(model)
hist(stud, freq=FALSE, main="Distribution of Studentized Residuals",
xlab="Studentized Residuals", ylab="Density", ylim=c(0,0.5))
install.packages(c('ggiraph','ggiraphExtra'))
knitr::opts_chunk$set(echo = FALSE)
library(usdm) #for multicollinearity
library(tidyverse)
library(ggplot2)
library(PerformanceAnalytics)
library(investr)
library(ggiraph)
library(ggiraphExtra)
ggPredict(model,interactive = TRUE)
model = lm(data=select(df.train,-JobName), formula = y3log ~ .)
ggPredict(model,interactive = TRUE)
names(model)
model
model = lm(data=select(df.train,-JobName,y3log,x1,x2), formula = y3log ~ .)
ggPredict(model,interactive = TRUE)
model = lm(data=select(df.train,-JobName,y3log,x1,x2), formula = y3log ~ .)
summary(model)
model = lm(data=select(df.train,-JobName,y3log,x1,x2), formula = y3log ~ .)
select(df.train,-JobName,y3log,x1,x2)
model = lm(data=select(df.train,y3log,x1,x2,x3), formula = y3log ~ .)
summary(model)
ggPredict(model,interactive = TRUE)
ggPredict(model,interactive = FALSE)
fit.lm = lm(data=select(df.train,-JobName), formula = y3log ~ .)
summary(fit.lm)
fit.lm.AIC=stepAIC(fit.lm,direction='backward')
library(MASS)
fit.lm.AIC=MASS::stepAIC(fit.lm,direction='backward')
library(glnet)
library(glmnet)
anova(fit.lm.AIC)
summary(fit.lm.AIC)
#http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/
fit.lm.AIC=MASS::stepAIC(fit.lm,direction='both')
#http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/
fit.lm.AIC=MASS::stepAIC(fit.lm,direction='both')
summary(fit.lm)
fit.lm.AIC=MASS::stepAIC(fit.lm,direction='both')
summary(fit.lm.AIC)
df.train.fit = select(df.train,-JobName)
df.train = df %>% sample_frac(.70)
df.test = df %>% anti_join(df, df.train, by = 'JobName')
df.train.fit = select(df.train,-JobName)
names(df.train)
df.train.fit = dplyr::select(df.train,-JobName)
fit.lm = lm(data=df.train.fit, formula = y3log ~ .)
summary(fit.lm)
# Stepwise
#http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/
fit.lm.AIC=MASS::stepAIC(fit.lm,direction='both')
summary(fit.lm.AIC)
summary(fit.lm)
saveRDS(fit.lm.AIC,'fit.lm.AIC.rds')
#residual plot
plot(fit.lm, which=c(1:3))
#residual plot
plot(fit.lm, which=c(1:3))
stud <- rstudent(fit.lm)
hist(fit.lm, freq=FALSE, main="Distribution of Studentized Residuals",
xlab="Studentized Residuals", ylab="Density", ylim=c(0,0.5))
stud <- rstudent(fit.lm)
stud
hist(fit.lm, freq=FALSE, main="Distribution of Studentized Residuals",
xlab="Studentized Residuals", ylab="Density", ylim=c(0,0.5))
hist(stud, freq=FALSE, main="Distribution of Studentized Residuals",
xlab="Studentized Residuals", ylab="Density", ylim=c(0,0.5))
plot(fit.lm.AIC, which=c(1:3))
plot(fit.lm.AIC, which=c(1:3))
stud <- rstudent(fit.lm.AIC)
hist(stud, freq=FALSE, main="Distribution of Studentized Residuals",
xlab="Studentized Residuals", ylab="Density", ylim=c(0,0.5))
library(glmnet)
install.packages('glmnet')
library(glmnet)
c<−glmnet ( a s . ma t rix ( mtcars [ −1] ) , mtcars [ , 1 ]
df.train[-y3log,]
as.matrix(df.train[predictors,])
df.train[predictors,]
names(df.train)
head(df.train[predictors,])
predictors
head(df.train['x1',])
df.train['x1']
df.train['x1',]
df.train['x1']
df.train[predictors]
as.matrix(df.train[,predictors])
c<−glmnet( as.matrix(df.train[,predictors]),df.train[target],parallel=T)
c<−glmnet( as.matrix(df.train[,predictors]),df.train[target])
c<−glmnet( x=as.matrix(df.train[,predictors]),y=df.train[target])
c = glmnet(x=as.matrix(df.train[,predictors]),y=df.train[target])
df.train[target]
c = glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target])
,target
target
df.train[target]
df.train['target']
target='y3log'
c = glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target])
c
plot(x)
plot(c)
c = glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target],standardize = T)
plot(c)
t
c = glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target],standardize = T)
plot(c)
c = glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target],standardize = T,alpha=1)
plot(c)
cv = cv.glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target],standardize=T,type.measure='mse',nfolds=10,alpha=1)
cv
plot(cv)
summary(cv)
summary(cv)
lasso = cv.glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target]
,standardize=T,type.measure='mse',nfolds=10,alpha=1)
lasso$lambda.1se
summary(lasso)
lasso
lambda = lasso$lambda.1se #https://stats.stackexchange.com/questions/70249/feature-selection-model-with-glmnet-on-methylation-data-pn
fit.lm.lasso <- glmnet(x, y, alpha = 0, lambda = lambda)
fit.lm.lasso <- glmnetx(as.matrix(df.train[,predictors]),y=df.train[,target]
, alpha = 0, lambda = lambda)
fit.lm.lasso <- glmnet(as.matrix(df.train[,predictors]),y=df.train[,target]
, alpha = 0, lambda = lambda)
summary(fit.lm.lasso)
fit.lm.lasso <- glmnet(as.matrix(df.train[,predictors]),y=df.train[,target]
, alpha = 1, lambda = lambda)
summary(fit.lm.lasso)
.
lasso = cv.glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target]
,standardize=T,type.measure='mse',nfolds=10,alpha=1)
lasso = cv.glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target]
,standardize=T,type.measure='mse',nfolds=10,alpha=1)
lasso
plot(fit.lm.lasso)
lasso = cv.glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target]
,standardize=T,type.measure='mse',nfolds=5,alpha=0)
lasso = cv.glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target]
,standardize=T,type.measure='mse',nfolds=5,alpha=0)
lasso
plot(lasso)
lambda = lasso$lambda.1se #https://stats.stackexchange.com/questions/70249/feature-selection-model-with-glmnet-on-methylation-data-pn
lambda
lasso
fit.lm.lasso = cv.glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target]
,standardize=T,type.measure='mse',nfolds=5,alpha=0)
fit.lm.lasso = cv.glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target]
,standardize=T,type.measure='mse',nfolds=5,alpha=0)
plot(fit.lm.lasso)
fit.lm.lasso
fit.lm.lasso
lambda = fit.lm.lasso$lambda.1se #https://stats.stackexchange.com/questions/70249/feature-selection-model-with-glmnet-on-methylation-data-pn
fit.lm.lasso$glmnet.fit$beta
predict(fit.lm.lasso,data.complete)
predict(fit.lm.lasso,df)
predict(fit.lm.lasso,s=lambda,newx=df.test)
lambda
lambda
df.test
names(df.test)
fit.lm.lasso
glmnet::predict.cv.glmnet(fit.lm.lasso,s=lambda,newx=as.matrix(df.test[],predictors]))
glmnet::predict.cv.glmnet(fit.lm.lasso,s=lambda,newx=as.matrix(df.test[,predictors]))
glmnet::predict.cv.glmnet(fit.lm.lasso,s='almbda.1se',newx=as.matrix(df.test[,predictors]))
glmnet::predict.cv.glmnet(fit.lm.lasso,s='lambda.1se',newx=as.matrix(df.test[,predictors]))
glmnet::predict.cv.glmnet(fit.lm.lasso,s='lambda.1se',newx=as.matrix(df.train[,predictors]))
MSD=Metrics::mse(df.train$y3log,pred)
pred = glmnet::predict.cv.glmnet(fit.lm.lasso,s='lambda.1se',newx=as.matrix(df.train[,predictors]))
MSD=Metrics::mse(df.train$y3log,pred)
MSD
MED=Metrics::mse(df.train$y3log,pred)
MSE=Metrics::mse(df.train$y3log,pred)
MSE=Metrics::mse(df.train$y3log,predict(fit.lm.AIC,df.train))
MSE
MSE=Metrics::mse(df.train$y3log,predict(fit.lm,df.train))
MSE
plot(predict,resid(fit.lm.lasso))
plot(pred,resid(fit.lm.lasso))
plot(fit.lm.lasso, which=c(1:3))
plot(fit.lm.lasso)
stud <- rstudent(fit.lm.lasso)
investr::plotFit(fit.lm.lasso,data=df.train,interval=c('both'),level=0.95, extend.range=T,shade=T)
ggPredict(fit.lm.lasso,interactive = FALSE)
ggPredict(pred,interactive = FALSE)
pred
plot(fit.lm.lasso)
summary(fit.lm.AIC) #ajd R2 = 0.2388
summary(fit.lm.lasso)
summary(fit.lm.lasso$glmnet.fit)
pred = glmnet::predict.cv.glmnet(fit.lm.lasso,s='lambda.1se',newx=as.matrix(df.train[,predictors]), type = 'coefficients')
pred
fit.lm.lasso = cv.glmnet(x=as.matrix(df.train[,predictors]),y=df.train[,target]
,standardize=T,type.measure='mse',nfolds=5,alpha=1)
plot(fit.lm.lasso)
fit.lm.lasso
#fit.lm.lasso
lambda = fit.lm.lasso$lambda.1se #https://stats.stackexchange.com/questions/70249/feature-selection-model-with-glmnet-on-methylation-data-pn
pred = glmnet::predict.cv.glmnet(fit.lm.lasso,s='lambda.1se',newx=as.matrix(df.train[,predictors]))#, type = 'coefficients')
MSE=Metrics::mse(df.train$y3log,pred)
MSE
plot(pred,resid(fit.lm.lasso))
plot(fit.lm.lasso)
ggplot(pred,resid(fit.lm.lasso))
plot(pred,resid(fit.lm.lasso))
ggplot(aes(x=pred,y=resid(fit.lm.lasso)))
plot(pred,resid(fit.lm.lasso))
plot(fit.lm.lasso)
fit.lm.lasso$cvlo
fit.lm.lasso$glmnet.fit
summary(fit.lm.lasso$glmnet.fit)
MSE
plot(fit.lm.lasso)
glmnet::predict.cv.glmnet(fit.lm.lasso,s='lambda.1se',newx=as.matrix(df.train[,predictors]), type = 'response')
glmnet::predict.cv.glmnet(fit.lm.lasso,s='lambda.1se',newx=as.matrix(df.train[,predictors]), type = 'coefficients')
glmnet::predict.cv.glmnet(fit.lm.lasso,s='lambda.1se',newx=as.matrix(df.train[,predictors]))
pred = glmnet::predict.cv.glmnet(fit.lm.lasso,s='lambda.1se',newx=as.matrix(df.train[,predictors]))#, type = 'coefficients')
head(pred)
MSE=Metrics::mse(df.train$y3log,pred)
MSE
plot(pred,resid(fit.lm.lasso))
fit.lm.lasso$glmnet.fit$dev.ratio
which(fit.lm.lasso$glmnet.fit$lambda == fit.lm.lasso$lambda.1se)
lambdaID=which(fit.lm.lasso$glmnet.fit$lambda ==lambda)
#https://stats.stackexchange.com/questions/70249/feature-selection-model-with-glmnet-on-methylation-data-pn
fit.lm.lasso$glmnet.fit$dev.ratio[lambdaID]
coef(fit.lm.lasso, s = "lambda.1se")
lambdaID=which(fit.lm.lasso$lambda.1se==lambda)
lambdaID
fit.lm.lasso$cvm[lambdaID]
e=fit.lm.lasso$cvm[lambdaID]
r2<-1-e/var(fundm)
r2
r2<-1-e/var(df.train[,target])
r2
e
#https://stats.stackexchange.com/questions/70249/feature-selection-model-with-glmnet-on-methylation-data-pn
fit.lm.lasso$glmnet.fit$dev.ratio[lambdaID]
e=fit.lm.lasso$cvm[lambdaID]
r2<-1-e/var(df.train[,target])
r2
r2
fit.lm.lasso
fit.lm.lasso$glmnet.fit$lambda
lambdaID=which(fit.lm.lasso$glmnet.fit$lambda==lambda)
lambdaID
e=fit.lm.lasso$cvm[lambdaID]
r2<-1-e/var(df.train[,target])
r2
e
1 - fit.lm.lasso$cvm/var(df.train[,target])
plot(fit.lm.lasso$glmnet.fit$lambda==lambda$lambda,rsq)
plot(fit.lm.lasso$lambda)
rsq = 1 - fit.lm.lasso$cvm/var(df.train[,target])
rsq
plot(fit.lm.lasso$lambda,rsq)
rsq[lambdaID]
r2
rsq[lambdaID]
r2s = 1 - fit.lm.lasso$cvm/var(df.train[,target])
plot(fit.lm.lasso$lambda,r2s)
fit.lm.lasso$glmnet.fit$dev.ratio[lambdaID]
r2s
rsq[lambdaID]
#https://stats.stackexchange.com/questions/70249/feature-selection-model-with-glmnet-on-methylation-data-pn
fit.lm.lasso$glmnet.fit$dev.ratio[lambdaID]
df.train.fit = dplyr::select(df.train,-JobName)
fit.lm = lm(data=df.train.fit, formula = y3log ~ .)
summary(fit.lm) # adj. R2 = 0.2248
#residual plot
plot(fit.lm, which=c(1:3))
stud <- rstudent(fit.lm)
hist(stud, freq=FALSE, main="Distribution of Studentized Residuals",
xlab="Studentized Residuals", ylab="Density", ylim=c(0,0.5))
MSE=Metrics::mse(df.train$y3log,predict(fit.lm,df.train))
MSE
fit.lm.AIC = readRDS('fit.lm.AIC.rds')
summary(fit.lm.AIC) #ajd R2 = 0.2388
res=resid(model)
plot(df$y13log,  res)
#chart.Correlation(select(data,-JobName),  pch=21)
t=round(cor(select(data.complete,-one_of(target,'JobName')),select_at(data.complete,target)),4)
t=round(cor(select(data.complete,-one_of('JobName'))),4)
knitr::opts_chunk$set(echo = FALSE)
library(usdm) #for multicollinearity
library(tidyverse)
library(ggplot2)
library(PerformanceAnalytics)
library(MASS)
library(glmnet)
library(investr)
library(ggiraph)
library(ggiraphExtra) #https://cran.r-project.org/web/packages/ggiraphExtra/vignettes/ggPredict.html
feat  = read.csv('../../Data/features.csv')
labels = read.csv('../../Data/labels.csv')
predictors = names(dplyr::select(feat,-JobName))
target = 'y3'
data = inner_join(feat,select_at(labels,c('JobName',target)),by='JobName')
data.cc  = complete.cases(data)
data.notComplete = data[! data.cc,]
data.complete = data[data.cc,]
message('Non-Complete cases: ',nrow(data.notComplete))
feat.cc  = complete.cases(feat)
feat.notComplete = feat[! feat.cc,]
feat.complete = feat[feat.cc,]
message('Non-Complete cases: ',nrow(feat.notComplete))
ggplot(gather(select_at(data,target)), aes(value)) +
geom_histogram(aes(y=..density..),bins = 50,fill='light blue') +
geom_density() +
facet_wrap(~key, scales = 'free',ncol=4)
print(summary(data$x11))
ggplot(gather(select_at(data,'x11')), aes(value)) +
geom_histogram(aes(y=..density..),bins = 50,fill='light blue') +
geom_density() +
facet_wrap(~key, scales = 'free',ncol=4)
ggplot(gather(select_at(data,predictors)), aes(value)) +
geom_histogram(aes(y=..density..),bins = 50,fill='light blue') +
geom_density() +
facet_wrap(~key, scales = 'free',ncol=4)
#chart.Correlation(select(data,-JobName),  pch=21)
t=round(cor(select(data.complete,-one_of(target,'JobName')),select_at(data.complete,target)),4)
target
select(data.complete,-one_of(target,'JobName'))
select(data.complete,-dplyr::one_of(target,'JobName'))
select(data.complete,-tidysellect::one_of(target,'JobName'))
one_of(target,'JobName')
install.packages('tidyselect')
install.packages("tidyselect")
install.packages('tidyselect')
install.packages("tidyselect")
install.packages("tidyselect")
knitr::opts_chunk$set(echo = FALSE)
library(usdm) #for multicollinearity
library(tidyverse)
knitr::opts_chunk$set(echo = FALSE)
library(usdm) #for multicollinearity
library(tidyverse)
library(tidyverse)
install.packages("tidyselect")
install.packages('tidyverse')
knitr::opts_chunk$set(echo = FALSE)
library(usdm) #for multicollinearity
library(tidyverse)
library(ggplot2)
library(PerformanceAnalytics)
library(MASS)
library(glmnet)
library(investr)
library(ggiraph)
library(ggiraphExtra) #https://cran.r-project.org/web/packages/ggiraphExtra/vignettes/ggPredict.html
knitr::opts_chunk$set(echo = FALSE)
library(usdm) #for multicollinearity
library(tidyverse)
library(ggplot2)
library(PerformanceAnalytics)
library(MASS)
library(glmnet)
library(investr)
library(ggiraph)
library(ggiraphExtra) #https://cran.r-project.org/web/packages/ggiraphExtra/vignettes/ggPredict.html
feat  = read.csv('../../Data/features.csv')
labels = read.csv('../../Data/labels.csv')
predictors = names(dplyr::select(feat,-JobName))
target = 'y3'
data = inner_join(feat,select_at(labels,c('JobName',target)),by='JobName')
data.cc  = complete.cases(data)
data.notComplete = data[! data.cc,]
data.complete = data[data.cc,]
message('Non-Complete cases: ',nrow(data.notComplete))
feat.cc  = complete.cases(feat)
feat.notComplete = feat[! feat.cc,]
feat.complete = feat[feat.cc,]
message('Non-Complete cases: ',nrow(feat.notComplete))
#chart.Correlation(select(data,-JobName),  pch=21)
t=round(cor(select(data.complete,-one_of(target,'JobName')),select_at(data.complete,target)),4)
select(data.complete,-one_of(target,'JobName'))
select_at(data.complete,-one_of(target,'JobName'))
select(data.complete,-one_of(target,'JobName'))
-one_of(target,'JobName')
one_of(target,'JobName')
tidyselect::one_of(target,'JobName')
tidyselect::one_of(c(target,'JobName'))
target
tidyselect::one_of(c('y','JobName'))
tidyselect::one_of(c('y3','JobName'))
vars_select(data.complete,tidyselect::one_of(c('y3','JobName')))
vars(data.complete,tidyselect::one_of(c('y3','JobName')))
nms <- names(iris)
vars_select(nms, starts_with("Petal"))
tidyselect::vars_select
nms <- names(iris)
tidyselect::vars_select(nms, starts_with("Petal"))
library(tidyselect)
nms <- names(iris)
tidyselect::vars_select(data.complete, one_of(target,'JobName'))
nms <- names(iris)
tidyselect::vars_select(data.complete, one_of(c(target,'JobName')))
tidyselect::vars_select(data.complete, one_of('JobName'))
tidyselect::vars_select(data.complete, tidyselect::one_of('JobName'))
select_all(data.complete,contains('JobName'))
select_all(as_tibble(data.complete),contains('JobName'))
install.packages(c("ggmap", "lme4", "modelr", "partykit", "pbapply", "raster"))
iris <- as_tibble(iris) # so it prints a little nicer
select(iris, starts_with("Petal"))
library(tidyverse)
iris <- as_tibble(iris) # so it prints a little nicer
select(iris, starts_with("Petal"))
iris <- as_tibble(iris) # so it prints a little nicer
select(iris, -starts_with("Petal"))
iris <- as_tibble(iris) # so it prints a little nicer
select(iris, -starts_with("Petal"."Species"))
iris <- as_tibble(iris) # so it prints a little nicer
select(iris, -starts_with(c("Petal"."Species")))
iris <- as_tibble(iris) # so it prints a little nicer
select(iris, -one_of("Petal"."Species"))
iris <- as_tibble(iris) # so it prints a little nicer
select(iris, -one_of("Petal"."Species")
iris <- as_tibble(iris) # so it prints a little nicer
select(iris, -one_of('Petal'.'Species'))
select(iris, -one_of('Petal'.'Species'))
select(iris, one_of('Petal'.'Species'))
select(iris, one_of('Petal','Species'))
select(iris, -one_of('Petal','Species'))
knitr::opts_chunk$set(echo = FALSE)
library(usdm) #for multicollinearity
knitr::opts_chunk$set(echo = FALSE)
library(usdm) #for multicollinearity
install.packages('raster')
knitr::opts_chunk$set(echo = FALSE)
library(usdm) #for multicollinearity
library(tidyverse)
library(ggplot2)
library(PerformanceAnalytics)
library(MASS)
library(glmnet)
library(investr)
library(ggiraph)
library(ggiraphExtra) #https://cran.r-project.org/web/packages/ggiraphExtra/vignettes/ggPredict.html
#chart.Correlation(select(data,-JobName),  pch=21)
t=round(cor(select(data.complete,-one_of(target,'JobName')),select_at(data.complete,target)),4)
#chart.Correlation(select(data,-JobName),  pch=21)
t=round(cor(dplyr::select(data.complete,-one_of(target,'JobName')),select_at(data.complete,target)),4)
#rsq http://myweb.uiowa.edu/pbreheny/7600/s16/notes/2-22.pdf
r2s = 1 - fit.lm.lasso$cvm/var(df.train[,target])
r2s[lambdaID]
